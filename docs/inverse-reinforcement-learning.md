---
layout: page
title: Inverse Reinforcement Learning
description: >
  Reading list on Inverse Reinforcement Learning
hide_description: true
sitemap: false
permalink: /docs/inverse-reinforcement-learning
---
Inverse Reinforcement Learning (IRL) is the machine learning paradigm concerned with inferring the latent reward function of an agent based on its observed behavior. Formally, given a Markov Decision Process (MDP) without a specified reward signal and a set of expert demonstrations (state-action trajectories), IRL seeks to recover the underlying utility function that the expert is assumed to be optimally maximizing. This effectively inverts the standard reinforcement learning problem: rather than deriving a policy from a known reward, it derives the reward structure that best explains the observed policy.

| **Title** | **Author / Year** | **Theme** | **Comment** |
|-----------|-------------------|-----------|-------------|
| [Maximum Entropy IRL](https://cdn.aaai.org/AAAI/2008/AAAI08-227.pdf) | Ziebart et al. (2008) | Algorithm | Methodological Paper |
| [Deep Maximum Entropy IRL](https://arxiv.org/pdf/1507.04888) | Wulfmeier et al. (2015) | Algorithm | Methodological Paper |
| [Adversarial Inverse Reinforcement Learning](https://arxiv.org/pdf/1710.11248) | Fu et al. (2018) | Algorithm | Methodological Paper |
| [Inverse soft-Q Learning for Imitation (Environment Free)](https://arxiv.org/pdf/2106.12142) | Garg et al. (2022) | Algorithm | Methodological Paper |
| [Variational IRL (Environment Free)](https://arxiv.org/pdf/1809.06404) | Qureshi et al. (2019) | Algorithm | Methodological Paper |
| [Multi-Agent Adversarial IRL](https://arxiv.org/pdf/1907.13220) | Yu et al. (2019) | Algorithmic Enhancement | Methodological Paper |
| [Context-aware IRL](https://www.sciencedirect.com/science/article/pii/S0952197625002799) | Liu et al. (2025) | Modeling human behavior using IRL | Application Paper |
| [IRL for modeling reservoir operations](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10552338) | Giuliani and Castelletti (2024) | Modeling human behavior using IRL | Application Paper |
| [Multiple Expert and Non-stationarity in IRL](https://link.springer.com/article/10.1007/s10994-020-05939-8) | Likmeta et al. (2021) | Modeling human behavior using IRL | Application Paper |
| [Advances and Applications in IRL](https://link.springer.com/article/10.1007/s00521-025-11100-0) | Deshpande et al. (2025) | Algorithms and Application | Literature Review |





			
